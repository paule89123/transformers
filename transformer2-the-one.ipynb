{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6d8dd942-3bfa-462a-9d96-96c33620d701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (4.39.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (2024.2.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fd7a629b-d6a9-4bb7-baaf-9e8ce80d804a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids [[101, 1996, 4937, 2938, 2006, 1996, 13523, 13523, 13523, 102], [101, 2045, 2003, 2751, 102], [101, 4873, 2058, 1996, 10098, 102], [101, 6721, 6251, 102]]\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define the short stories\n",
    "stories = [\"The cat sat on the mat\", \"There is gold\", \"Somewhere over the rainbow\", \"Random sentence\"]\n",
    "\n",
    "# Tokenize the stories and convert them to input IDs\n",
    "input_ids = []\n",
    "for story in stories:\n",
    "    encoded_story = tokenizer.encode(story, add_special_tokens=True)\n",
    "    input_ids.append(encoded_story)\n",
    "\n",
    "print(\"input_ids\", input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ca68f4ba-282e-483e-a21b-439dcd71195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story_embeddings [tensor([[[-0.2599,  0.0782,  0.0374,  ..., -0.1910,  0.2220,  0.2473],\n",
      "         [-0.4218, -0.1978, -0.2823,  ..., -0.2741,  0.9405, -0.5086],\n",
      "         [-0.3659, -0.0945,  0.2970,  ..., -0.3415,  0.6979,  0.6504],\n",
      "         ...,\n",
      "         [ 0.1764, -0.0344,  0.4185,  ..., -0.1668,  0.0158,  0.4952],\n",
      "         [-0.3249, -0.4096,  0.1259,  ...,  0.5783,  0.6253, -0.2562],\n",
      "         [ 0.6688,  0.0528, -0.3455,  ...,  0.1711, -0.3499, -0.3942]]]), tensor([[[-0.3443,  0.3713, -0.3405,  ..., -0.1429,  0.2200,  0.4851],\n",
      "         [-0.5444, -0.0672, -0.4171,  ..., -0.1206,  0.8002, -0.0201],\n",
      "         [-0.0833, -0.2276, -0.2673,  ...,  0.0262,  0.2740,  0.7333],\n",
      "         [-0.7732, -0.1943, -0.2901,  ...,  0.4301,  0.5311, -0.0250],\n",
      "         [ 0.9799,  0.1183, -0.2731,  ...,  0.2572, -0.6214, -0.2615]]]), tensor([[[-0.0177,  0.0610,  0.0319,  ..., -0.2689,  0.0759,  0.0701],\n",
      "         [-0.3163,  0.4928, -0.4013,  ..., -0.4979,  0.2614,  0.7672],\n",
      "         [ 0.2041,  0.0082,  0.0941,  ..., -0.6587,  0.3770,  0.5613],\n",
      "         [-0.4539, -0.2633, -0.0198,  ..., -0.3522,  0.1080, -0.1467],\n",
      "         [-0.5809, -0.1935, -0.1369,  ...,  0.2229,  0.0346, -0.7004],\n",
      "         [ 0.9920,  0.1162, -0.3374,  ..., -0.2021, -0.6771, -0.3637]]]), tensor([[[-0.2042,  0.0375, -0.2100,  ..., -0.1394, -0.0867,  0.3105],\n",
      "         [ 0.0412, -0.3551, -0.1115,  ...,  0.0488, -0.2621,  0.0481],\n",
      "         [-0.0759, -0.6814, -0.1908,  ...,  0.2301, -0.0530, -0.2582],\n",
      "         [ 0.9654,  0.0099, -0.3011,  ...,  0.2264, -0.7522, -0.2054]]])]\n"
     ]
    }
   ],
   "source": [
    "# Generate BERT embeddings for each story\n",
    "story_embeddings = []\n",
    "with torch.no_grad():\n",
    "    for ids in input_ids:\n",
    "        embeddings = bert_model(torch.tensor([ids]))[0]\n",
    "        story_embeddings.append(embeddings)\n",
    "\n",
    "print(\"story_embeddings\", story_embeddings)\n",
    "\n",
    "# Determine the maximum sequence length among the stories\n",
    "max_length = max(len(ids) for ids in input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "91202e8f-f543-43bb-90e4-6bf0e6e71a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_tokens [tensor([ 1996,  4937,  2938,  2006,  1996, 13523, 13523, 13523,   102]), tensor([2045, 2003, 2751,  102]), tensor([ 4873,  2058,  1996, 10098,   102]), tensor([6721, 6251,  102])]\n"
     ]
    }
   ],
   "source": [
    "# Pad the story embeddings\n",
    "padded_story_embeddings = []\n",
    "for embeddings in story_embeddings:\n",
    "    padded_embeddings = torch.zeros(1, max_length, embeddings.shape[-1])\n",
    "    padded_embeddings[0, :embeddings.shape[1], :] = embeddings[0]\n",
    "    padded_story_embeddings.append(padded_embeddings)\n",
    "\n",
    "# Define the target tokens for each story\n",
    "target_tokens = []\n",
    "for ids in input_ids:\n",
    "    target_ids = ids[1:]  # Shift the input tokens by one position\n",
    "    target_tokens.append(torch.tensor(target_ids))\n",
    "\n",
    "print(\"target_tokens\", target_tokens)\n",
    "\n",
    "# Pad the target tokens\n",
    "padded_target_tokens = []\n",
    "for tokens in target_tokens:\n",
    "    padded_tokens = torch.zeros(max_length, dtype=torch.long)\n",
    "    padded_tokens[:len(tokens)] = tokens\n",
    "    padded_target_tokens.append(padded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "59bba726-0608-434e-ae11-e495eac5d3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size 30522\n"
     ]
    }
   ],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers, dim_feedforward, vocab_size):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model, nhead, dim_feedforward)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers)\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, target, memory):\n",
    "        target = self.embedding(target) * math.sqrt(d_model)\n",
    "        target = self.pos_encoder(target)\n",
    "        output = self.transformer_decoder(target, memory)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "# Hyperparameters\n",
    "d_model = 768  # Same as BERT's hidden size\n",
    "nhead = 8\n",
    "num_layers = 6\n",
    "dim_feedforward = 2048\n",
    "vocab_size = len(tokenizer.vocab)\n",
    "print(\"vocab_size\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4d03e6dc-4218-4bfa-9d17-410318d04c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the decoder\n",
    "decoder = TransformerDecoder(d_model, nhead, num_layers, dim_feedforward, vocab_size)\n",
    "\n",
    "# Training hyperparameters\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 10\n",
    "batch_size = 2\n",
    "\n",
    "# Create a dataset and data loader\n",
    "dataset = TensorDataset(torch.stack(padded_story_embeddings), torch.stack(padded_target_tokens))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b1a663e9-c3fa-4e2c-a4df-3cb29e59ba47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 8.2134\n",
      "Epoch [2/10], Loss: 3.5438\n",
      "Epoch [3/10], Loss: 4.9063\n",
      "Epoch [4/10], Loss: 4.0790\n",
      "Epoch [5/10], Loss: 1.8305\n",
      "Epoch [6/10], Loss: 1.5955\n",
      "Epoch [7/10], Loss: 1.6217\n",
      "Epoch [8/10], Loss: 2.0823\n",
      "Epoch [9/10], Loss: 1.3523\n",
      "Epoch [10/10], Loss: 1.3933\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get the decoder inputs and target tokens for the current batch\n",
    "        decoder_inputs, target_tokens = batch\n",
    "        \n",
    "        # Reshape the decoder inputs and target tokens\n",
    "        decoder_inputs = decoder_inputs.view(batch_size, max_length, -1)\n",
    "        target_tokens = target_tokens.view(batch_size, -1)\n",
    "        \n",
    "        # Forward pass\n",
    "        decoder_outputs = decoder(target_tokens, decoder_inputs)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(decoder_outputs.view(-1, vocab_size), target_tokens.view(-1))\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fce189e5-8a7e-4f45-a8e3-a2cace4dc2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] the cat [SEP] [SEP]\n"
     ]
    }
   ],
   "source": [
    "# Text generation\n",
    "def generate_text(prompt, max_length=50):\n",
    "    # Tokenize the prompt\n",
    "    prompt_ids = tokenizer.encode(prompt, add_special_tokens=True)\n",
    "    prompt_tensor = torch.tensor([prompt_ids])\n",
    "\n",
    "    # Generate BERT embeddings for the prompt\n",
    "    with torch.no_grad():\n",
    "        prompt_embeddings = bert_model(prompt_tensor)[0]\n",
    "\n",
    "    # Initialize the generated sequence with the prompt\n",
    "    generated_seq = prompt_ids\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        # Get the decoder input and target tokens\n",
    "        decoder_input = prompt_embeddings[:, :len(generated_seq), :]\n",
    "        target_token = torch.tensor([generated_seq])\n",
    "\n",
    "        # Pad the decoder input and target tokens\n",
    "        decoder_input_padded = torch.zeros(1, len(generated_seq), decoder_input.shape[-1])\n",
    "        decoder_input_padded[0, :decoder_input.shape[1], :] = decoder_input\n",
    "        target_token_padded = torch.zeros(len(generated_seq), dtype=torch.long)\n",
    "        target_token_padded[:len(target_token[0])] = target_token[0]\n",
    "\n",
    "        # Forward pass\n",
    "        decoder_output = decoder(target_token_padded.unsqueeze(0), decoder_input_padded)\n",
    "\n",
    "        # Get the predicted token\n",
    "        predicted_token = decoder_output.argmax(dim=-1)[0, -1].item()\n",
    "\n",
    "        # Append the predicted token to the generated sequence\n",
    "        generated_seq.append(predicted_token)\n",
    "\n",
    "        # Stop generation if the end-of-sequence token is predicted\n",
    "        if predicted_token == tokenizer.sep_token_id:\n",
    "            break\n",
    "\n",
    "    # Decode the generated sequence\n",
    "    generated_text = tokenizer.decode(generated_seq)\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "# Example usage\n",
    "prompt = \"The cat\"\n",
    "generated_story = generate_text(prompt)\n",
    "print(generated_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bad391f-2aa7-41c0-8aa7-a00fdf65c93f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
